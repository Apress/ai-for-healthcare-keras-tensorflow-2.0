{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mednli_path = \"./nli_task\"\n",
    "mednli_bionlp = os.path.join(mednli_path,\"mednli_bionlp\")\n",
    "mednli_clinical = os.path.join(mednli_path,\"mednli_clinical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIONLP\n",
    "import pandas as pd    \n",
    "nli_obj = pd.read_json(path_or_buf=os.path.join(mednli_bionlp,\"mednli_bionlp19_shared_task.jsonl\"), lines=True)\n",
    "nli_labels = pd.read_csv(os.path.join(mednli_bionlp,\"mednli_bionlp19_shared_task_ground_truth.csv\"), index_col = None)\n",
    "\n",
    "# Merging with labels\n",
    "bionlp_nli = pd.merge(nli_obj, nli_labels, left_on = \"pairID\", right_on = \"pair_id\", how = \"left\")[[\"sentence1\",\"sentence2\",\"label\"]]\n",
    "bionlp_nli[\"data\"] = \"bionlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical\n",
    "import pandas as pd    \n",
    "nli_dev_obj = pd.read_json(path_or_buf=os.path.join(mednli_clinical,\"mli_dev_v1.jsonl\"), lines=True)\n",
    "nli_train_obj = pd.read_json(path_or_buf=os.path.join(mednli_clinical,\"mli_train_v1.jsonl\"), lines=True)\n",
    "\n",
    "# merging training and dev set\n",
    "clinical_nli = pd.concat([nli_train_obj,nli_dev_obj], axis = 0)[[\"sentence1\",\"sentence2\",\"gold_label\"]]\n",
    "clinical_nli.columns = [\"sentence1\",\"sentence2\",\"label\"]\n",
    "clinical_nli[\"data\"] = \"clinical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset\n",
    "med_nli = pd.concat([bionlp_nli,clinical_nli], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n",
    "##### Code Adapted from https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/nli/training_nli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gsarti/covidbert-nli\"\n",
    "# Read the dataset\n",
    "train_batch_size = 32\n",
    "model_save_path = 'output/training_nli_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model._target_device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "train_samples = []\n",
    "for i,row in  med_nli.iterrows():\n",
    "    label_id = label2int[row['label']]\n",
    "    train_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=label_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=len(label2int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Configure the training\n",
    "num_epochs = 5\n",
    "\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=model_save_path\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pre_trained = SentenceTransformer(\"./output/training_nli_covidbert-mednli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Med-Marco Fine-Tuning\n",
    "\n",
    "The medical subset of the MS-MARCO dataset was constructed for SLEDGE by filtering queries that have terms found in MedSyn, a lexicon of layman and expert medical terminology. The full list of MS-MARCO training IDs that match the filter are found here.\n",
    "\n",
    "MedSyn :- http://ir.cs.georgetown.edu/downloads/ECIR2013-ADRTrace.pdf\n",
    "\n",
    "Med-MSMArco :- https://github.com/Georgetown-IR-Lab/covid-neural-ir/blob/master/med-msmarco-train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "msmarco_filepath = \"./msmarco_task/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical Q-Ids\n",
    "med_qids = []\n",
    "with open(os.path.join(msmarco_filepath,\"med-msmarco.txt\")) as f:\n",
    "    for line in f:\n",
    "        med_qids.append(int(line.replace(\"\\n\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 100000\n",
    "\n",
    "# create the iterator\n",
    "msmarco_iterator = pd.read_csv(\n",
    "    os.path.join(msmarco_filepath,\"qidpidtriples.rnd-shuf.train.tsv\"),\n",
    "    iterator=True,\n",
    "    chunksize=n_rows,\n",
    "    sep = \"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_msmarco = pd.concat([msmarco_chunk[msmarco_chunk.iloc[:,0].isin(med_qids)]\n",
    "    for msmarco_chunk in msmarco_iterator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_msmarco.columns = [\"qid\", \"pos_id\", \"neg_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# med_msmarco2 = pd.read_csv(\n",
    "#     os.path.join(msmarco_filepath,\"qidpidtriples.rnd-shuf.train-eval.tsv\"),\n",
    "#     sep = \"\\t\", header = None)\n",
    "\n",
    "# med_msmarco2.columns = [\"qid\", \"pos_id\", \"neg_id\"]\n",
    "\n",
    "# len(set(med_qids) - set(med_msmarco[\"qid\"].tolist() + med_msmarco2[\"qid\"].tolist()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_msmarco.groupby([\"qid\",\"pos_id\"]).head(4).reset_index().to_csv(\"medmarco.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfqna",
   "language": "python",
   "name": "tfqna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
