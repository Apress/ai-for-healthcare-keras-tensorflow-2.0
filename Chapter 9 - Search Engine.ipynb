{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Passage Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bansa\\AppData\\Roaming\\Python\\Python37\\site-packages\\IPython\\core\\interactiveshell.py:3147: DtypeWarning: Columns (1,4,5,13,14,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\bansa\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_dir = \"./Data/\"\n",
    "metadata_path = os.path.join(data_dir,\"metadata.csv\")\n",
    "metadata_df = pd.read_csv(metadata_path,\n",
    "                               dtype={'Microsoft Academic Paper ID': str, 'pubmed_id': str})\n",
    "metadata_df = metadata_df.dropna(subset=['abstract', 'title']).reset_index(drop=True)\n",
    "metadata_df = metadata_df.drop_duplicates(['abstract', 'title']).reset_index(drop = True)\n",
    "\n",
    "#Subsetting Columns\n",
    "final_metadata = metadata_df[['abstract', 'title']]\n",
    "final_metadata[\"id\"] = [str(i) for i in range(final_metadata.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('./pre_trained_model/training_nli_covidbert-mednli/0_Transformer')\n",
    "MAX_LEN = 300\n",
    "STRIDE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_para_segments(text, stride, max_len, id_, title, tokenizer):\n",
    "    \"\"\"\n",
    "    Get Running length window of certain length with a paritcular stride\n",
    "    \"\"\"\n",
    "#     tokenizer = AutoTokenizer.from_pretrained('./pre_trained_model/training_nli_covidbert-mednli/0_Transformer')\n",
    "    text_map = {i:sent for i, sent in enumerate(sent_tokenize(text))}\n",
    "    text_lenmap = {i:len(input_id) for i,input_id in enumerate(tokenizer(list(text_map.values()))['input_ids'])}\n",
    "    \n",
    "    para = []\n",
    "    i = 0\n",
    "    if len(text_map) > 1:\n",
    "        while i < len(text_map):\n",
    "            for j in text_map.keys():\n",
    "                if j > i:\n",
    "                    new_para_sub_len = np.sum(list(text_lenmap.values())[i:j])\n",
    "                    if j == (len(text_map) -1):\n",
    "                        para.append(\"\".join(list(text_map.values())[i:(j+1)]))\n",
    "                        i = 999999 # some big value\n",
    "                    if new_para_sub_len <= max_len:\n",
    "                        continue\n",
    "                    else:                                                 \n",
    "                        para.append( \"\".join(list(text_map.values())[i:j]))\n",
    "                        i = i+stride\n",
    "    else:\n",
    "        para.append(text_map[0])\n",
    "        \n",
    "    # at least 5 words should be there in the paragraph\n",
    "    # para = [paragraph for paragraph in para if len(paragraph.split()) > 5]\n",
    "    return [[id_, str(id_) + \"_\" + str(i), title, paragraph] for i,paragraph in enumerate(para)]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import pickle\n",
    "\n",
    "# for i,df in enumerate(np.array_split(final_metadata, 10)):\n",
    "#     print(i)\n",
    "#     passage_list = [get_para_segments(row[\"abstract\"],STRIDE, MAX_LEN,row[\"id\"],\n",
    "#                                       row[\"title\"], TOKENIZER) for i,row in tqdm(df.iterrows())]\n",
    "#     with open('./Data/passage/passage_'+str(i)+'.pkl', 'wb') as f:\n",
    "#         pickle.dump(passage_list, f)\n",
    "#         del passage_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert QE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "all_metadata = []\n",
    "for i,files in enumerate(glob.glob(\"./Data/passage/passage_*.pkl\")):\n",
    "    with open(files, 'rb') as f:\n",
    "        data_list = pickle.load(f)\n",
    "        all_metadata.extend([data_pair for data in data_list \\\n",
    "                             for data_pair in data])\n",
    "\n",
    "all_metadata_df = pd.DataFrame(all_metadata, columns = [\"id\",\"passage_id\",\"title\",\"passage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# json_lines = [{'id': row['passage_id'], 'contents': row['passage']} for i,row in all_metadata_df.iterrows()]\n",
    "\n",
    "# with open(\"./Data/passage_data.jsonl\", 'w') as f:\n",
    "#     for lines in json_lines:\n",
    "#         f.write(json.dumps(lines) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import SimpleSearcher\n",
    "bm25 = SimpleSearcher('./Data/indexes')\n",
    "\n",
    "# search_hits = bm25.search('what is coronavirus', k= 200)\n",
    "# bm25_passage = [hit.docid for hit in search_hits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import nltk\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25RankedResults:\n",
    "    \"\"\"\n",
    "    BM25 Results from the abstract.\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    bm25 = BM25RankedResults(metadata_df) # metadata_df is a pandas dataframe with 'title' and 'abstract' columns \n",
    "    topbm25 = bm25.search(\"What is coronavirus\", num=10) # Return `num` top-results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, corpus: pd.DataFrame):\n",
    "        self.corpus = corpus\n",
    "        self.columns = corpus.columns\n",
    "        token_list = pd.Series([[str(token) for token in doc if str(token)] \\\n",
    "         for doc in tokenizer.pipe(corpus.passage, \n",
    "                                   batch_size=5000)])\n",
    "        self.index = token_list.to_frame()\n",
    "        self.index.columns = ['terms']\n",
    "        self.index.index = self.corpus.index\n",
    "        self.bm25 = BM25Okapi(self.index.terms.tolist())\n",
    "        \n",
    "        self.bm25 = BM25Okapi(token_list)\n",
    "    \n",
    "    def search(self, query, num = 200):\n",
    "        \"\"\"\n",
    "        Return top `num` results that better match the query\n",
    "        \"\"\"\n",
    "        search_terms = query.split() \n",
    "        doc_scores = self.bm25.get_scores(search_terms) # get scores\n",
    "        \n",
    "        ind = np.argsort(doc_scores)[::-1][:num] # sort results\n",
    "        \n",
    "        results = self.corpus.iloc[ind][self.columns] # Initialize results_df\n",
    "        results['score'] = doc_scores[ind] # Insert 'score' column\n",
    "        results = results[results.score > 0]\n",
    "        return results.passage_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passage_data = all_metadata_df.sample(5000)\n",
    "# bm25_okapi = BM25RankedResults(passage_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception when trying to download https://sbert.net/models/deepset/covid_bert_base.zip. Response 404\n",
      "SentenceTransformer-Model https://sbert.net/models/deepset/covid_bert_base.zip not found. Try to create it from scratch\n",
      "Try to create Transformer Model deepset/covid_bert_base with mean pooling\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "covid_bert =  SentenceTransformer(\"deepset/covid_bert_base\", device = 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_vals(list1, list2, k = 100, model = covid_bert, return_cosine_mat = False):\n",
    "    # Compute embedding for both lists\n",
    "    embeddings1 = model.encode(list1, convert_to_tensor = True)\n",
    "    embeddings2 = model.encode(list2, convert_to_tensor = True)\n",
    "    \n",
    "    # Compute cosine-similarity\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    \n",
    "    if return_cosine_mat:\n",
    "        return cosine_scores.numpy()\n",
    "    \n",
    "    # Select top kd documents/passage\n",
    "    _topkd = np.argsort(cosine_scores.numpy()[0])[::-1][:k]\n",
    "    \n",
    "    return _topkd, cosine_scores.numpy()[0][_topkd]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def bert_qe(query, bm25_model, passage_id_map, bert_model = covid_bert, \n",
    "            alpha = 0.4, document_size = 500, chunk_size = 8):\n",
    "    \"\"\"\n",
    "    Re-ranks BM-25 document based on relevancy of query to chunks of a passage.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\tPhase 1\")\n",
    "    # Phase 1\n",
    "    topbm25 = bm25_model.search(query, document_size)\n",
    "    \n",
    "    #doc index to passage map\n",
    "    passage_index_map = OrderedDict({idx:passage_id_map[passages] if isinstance(passages,str) \\\n",
    "                               else passage_id_map[passages.docid] for idx,passages in enumerate(topbm25)})\n",
    "    passageid_index_map = OrderedDict({idx:passages if isinstance(passages,str) \\\n",
    "                               else passages.docid for idx,passages in enumerate(topbm25)})\n",
    "    \n",
    "    _topdocidx, _topdocscores = get_top_k_vals([query], \n",
    "                                         list(passage_index_map.values()),\n",
    "                                         k = document_size, model = bert_model)\n",
    "    # Store Top Contextually matching docs\n",
    "    passage_scores = {idx:score for idx,score in zip(_topdocidx, _topdocscores)}\n",
    "    \n",
    "    \n",
    "    print(\"\\tPhase 2\")\n",
    "    # Phase 2\n",
    "    # Create chunks of length \"n\" and stride them with a length of \"n/2\"\n",
    "    _chunks = [[\" \".join(phrase) for i, phrase in enumerate(nltk.ngrams(passage_index_map[idx].split(), \n",
    "                                                                        chunk_size)) if i%(chunk_size/2)==0] for idx in _topdocidx]\n",
    "    \n",
    "    # Flatten the list\n",
    "    all_chunks = list(chain.from_iterable(_chunks))\n",
    "    \n",
    "    # Get top chunks based on relevancy score with the query\n",
    "    _topchunkidx, _topchunkscores = get_top_k_vals([query], \n",
    "                                         all_chunks, \n",
    "                                         k = int(len(all_chunks)/2), model = bert_model)\n",
    "    \n",
    "    top_chunks = np.array(all_chunks)[_topchunkidx]\n",
    "    \n",
    "    # Apply softmax over query and chunk relevancy score, \n",
    "    # This acts as weights to chunk and document relevancy\n",
    "    _topchunksoftmax = softmax(_topchunkscores)\n",
    "    \n",
    "    \n",
    "    # Phase 3\n",
    "    print(\"\\tPhase 3\")\n",
    "    scores = get_top_k_vals(list(passage_index_map.values()), \n",
    "                            list(top_chunks), \n",
    "                            k = len(top_chunks), \n",
    "                            model = bert_model, \n",
    "                            return_cosine_mat = True)\n",
    "    \n",
    "    # Multiply the weights of chunk with query to relevancy of chunk with the document\n",
    "    # and sum over all the top chunks (kc in the paper)\n",
    "    docchunk_score = np.sum(np.multiply(_topchunksoftmax, np.array(scores)), axis = 1)\n",
    "         \n",
    "    # weighing importance of query relevance and query chunk-doc relevance\n",
    "    \n",
    "    final_score = alpha*_topdocscores + (1-alpha)*docchunk_score\n",
    "    \n",
    "    passage_score = dict(zip([passageid_index_map[idx] for idx in _topdocidx],final_score))\n",
    "\n",
    "    return passage_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the sentence-level covid-BERT NLI model\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "covid_nli = SentenceTransformer('./pre_trained_model/training_nli_covidbert-mednli', device = 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert abstracts to vectors\n",
    "# embeddings = covid_nli.encode(all_metadata_df.passage.to_list()[:100], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Building FAISS Index\n",
    "# embeddings = np.array([embedding for embedding in embeddings]).astype(\"float32\")\n",
    "\n",
    "# # Instantiate the index\n",
    "# embedding_index = faiss.IndexFlatIP(embeddings.shape[1])\n",
    "\n",
    "# # Pass the passage index to IndexIDMap\n",
    "# embedding_index = faiss.IndexIDMap(embedding_index)\n",
    "\n",
    "# # Numerical map\n",
    "# passage_num_map = {i:x for i,x in enumerate(all_metadata_df.passage_id.values)}\n",
    "\n",
    "# # Add vectors and their IDs\n",
    "# embedding_index.add_with_ids(embeddings, np.array(list(passage_num_map.keys()), np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = faiss.read_index(\"./Data/faiss_cord-19-passage.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Ranking on MedMarco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "covid_marco = CrossEncoder(\"./pre_trained_model/training_medmarco_covidbert\", device = 'cuda')\n",
    "\n",
    "# # Check if GPU is available and use it\n",
    "# if torch.cuda.is_available():\n",
    "#     covid_marco = covid_marco.to(torch.device(\"cuda\"))\n",
    "# print(covid_marco.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_passages(query, bm25_model, bert_model, passage_id_map, faiss_index, bert_qe_alpha = 0.4):\n",
    "    \n",
    "    print(\"Step 1 : BERT-QE Expansion\")\n",
    "    #BERT-QE\n",
    "    bertqe_dict = bert_qe(query, bm25_model = bm25_model, passage_id_map = passage_id_map,\n",
    "        bert_model = bert_model, alpha = 0.4, document_size = 500, chunk_size = 8)\n",
    "    \n",
    "    print(\"Step 2 : Semantic Passage Retrieval\")\n",
    "    # Semantic Search\n",
    "    _,indices = faiss_index.search(np.expand_dims(covid_nli.encode(query), axis = 0), k=500)\n",
    "    semantic_passage_ids = [passage_num_map[idx] for idx in indices[0]]\n",
    "    \n",
    "    # passages to be re-ranked\n",
    "    total_passage_ids = list(bertqe_dict.keys())+ semantic_passage_ids\n",
    "    \n",
    "    return list(set(total_passage_ids))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model used for comprehension\n",
    "from transformers import pipeline\n",
    "comprehension_model = pipeline(\"question-answering\", model='graviraja/covidbert_squad',\n",
    "                               tokenizer='graviraja/covidbert_squad', device=-1,use_fast = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_kaggle_questions = [\n",
    "          {\n",
    "              \"task\": \"What is known about transmission, incubation, and environmental stability?\",\n",
    "              \"questions\": [\n",
    "                  \"Is the virus transmitted by aerosol, droplets, food, close contact, fecal matter, or water?\",\n",
    "                  \"How long is the incubation period for the virus?\",\n",
    "                  \"Can the virus be transmitted asymptomatically or during the incubation period?\",\n",
    "                  \"How does weather, heat, and humidity affect the transmission of 2019-nCoV?\",\n",
    "                  \"How long can the 2019-nCoV virus remain viable on common surfaces?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"What do we know about COVID-19 risk factors?\",\n",
    "              \"questions\": [\n",
    "                  \"What risk factors contribute to the severity of 2019-nCoV?\",\n",
    "                  \"How does hypertension affect patients?\",\n",
    "                  \"How does heart disease affect patients?\",\n",
    "                  \"How does copd affect patients?\",\n",
    "                  \"How does smoking affect patients?\",\n",
    "                  \"How does pregnancy affect patients?\",\n",
    "                  \"What is the fatality rate of 2019-nCoV?\",\n",
    "                  \"What public health policies prevent or control the spread of 2019-nCoV?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"What do we know about virus genetics, origin, and evolution?\",\n",
    "              \"questions\": [\n",
    "                  \"Can animals transmit 2019-nCoV?\",\n",
    "                  \"What animal did 2019-nCoV come from?\",\n",
    "                  \"What real-time genomic tracking tools exist?\",\n",
    "                  \"What geographic variations are there in the genome of 2019-nCoV?\",\n",
    "                  \"What efforts are being done in asia to prevent further outbreaks?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"What do we know about vaccines and therapeutics?\",\n",
    "              \"questions\": [\n",
    "                  \"What drugs or therapies are being investigated?\",\n",
    "                  \"Are anti-inflammatory drugs recommended?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"What do we know about non-pharmaceutical interventions?\",\n",
    "              \"questions\": [\n",
    "                  \"Which non-pharmaceutical interventions limit transmission?\",\n",
    "                  \"What are the most important barriers to compliance?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"What has been published about medical care?\",\n",
    "              \"questions\": [\n",
    "                  \"How does extracorporeal membrane oxygenation affect 2019-nCoV patients?\",\n",
    "                  \"What telemedicine and cybercare methods are most effective?\",\n",
    "                  \"How is artificial intelligence being used in real time health delivery?\",\n",
    "                  \"What adjunctive or supportive methods can help patients?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"What do we know about diagnostics and surveillance?\",\n",
    "              \"questions\": [\n",
    "                  \"What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV?\"\n",
    "              ]\n",
    "          },\n",
    "          {\n",
    "              \"task\": \"Other interesting questions\",\n",
    "              \"questions\": [\n",
    "                  \"What is the immune system response to 2019-nCoV?\",\n",
    "                  \"Can personal protective equipment prevent the transmission of 2019-nCoV?\",\n",
    "                  \"Can 2019-nCoV infect patients a second time?\"\n",
    "              ]\n",
    "          }\n",
    "   ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covid_kaggle_questions = [{'task':'others','questions':[\"How does covid 19 affect smokers\",\n",
    "#                                                        \"what are common symptoms observed in covid 19 patient\",\n",
    "#                                                        \"how does co-existing viral infections affect transmission\",\n",
    "#                                                        \"What do we know about covid 19 in pregant womens\"]},\n",
    "#                          {\n",
    "#               \"task\": \"Other interesting questions\",\n",
    "#               \"questions\": [\n",
    "#                   \"What is the immune system response to 2019-nCoV\",\n",
    "#                   \"Can personal protective equipment prevent the transmission of 2019-nCoV\",\n",
    "#                   \"Can 2019-nCoV infect patients a second time\"\n",
    "#               ]\n",
    "#           }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking Passages for 1 of 4 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n",
      "Ranking Passages for 2 of 4 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n",
      "Ranking Passages for 3 of 4 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n",
      "Ranking Passages for 4 of 4 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n",
      "Ranking Passages for 1 of 3 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n",
      "Ranking Passages for 2 of 3 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n",
      "Ranking Passages for 3 of 3 query/queries\n",
      "Step 1 : BERT-QE Expansion\n",
      "\tPhase 1\n",
      "\tPhase 2\n",
      "\tPhase 3\n",
      "Step 2 : Semantic Passage Retrieval\n",
      "Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \n",
      "Step 4 : Comprehension \n"
     ]
    }
   ],
   "source": [
    "# Map of Passage id to Passage Text\n",
    "passage_id_map = pd.Series(all_metadata_df.passage.values,index=all_metadata_df.passage_id).to_dict()\n",
    "\n",
    "# Numerical map for semantic passage retreival\n",
    "passage_num_map = pd.Series(all_metadata_df.passage_id.values,index=pd.Series(range(len(all_metadata_df)))).to_dict()\n",
    "\n",
    "# Map of Passage id to Paper Title\n",
    "passage_id_title_map = pd.Series(all_metadata_df.title.values,index=all_metadata_df.passage_id).to_dict()\n",
    "\n",
    "\n",
    "all_comprehension_df_list = []\n",
    "#Search in a loop for the individual queries\n",
    "for task_query_dict in covid_kaggle_questions:\n",
    "    for i,query in enumerate(task_query_dict[\"questions\"]):\n",
    "        print(f\"Ranking Passages for {i+1} of {len(task_query_dict['questions'])} query/queries\")\n",
    "        passage_ids = get_ranked_passages(query, bm25_model = bm25, passage_id_map = passage_id_map,\n",
    "                                          bert_model = covid_bert,\n",
    "                                          faiss_index = embedding_index, bert_qe_alpha = 0.4)\n",
    "\n",
    "\n",
    "        #Concatenate the query and all passages and predict the scores for the pairs [query, passage]\n",
    "        model_inputs = [[query, passage_id_map[passage_id]] for passage_id in passage_ids]\n",
    "\n",
    "        print(\"Step 3 : Passage Re-ranking using Fine-Tuned Covid BERT \")\n",
    "        scores = covid_marco.predict(model_inputs)\n",
    "\n",
    "        #Sort the scores in decreasing order\n",
    "        results = [{'input': inp, 'score': score} for inp, score in zip(passage_ids, scores)]\n",
    "        results = sorted(results, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        # Filtering passages above a certain threshold\n",
    "        final_results = {res_dict['input']:res_dict['score'] for res_dict in results if res_dict['score'] > 0.3}\n",
    "        \n",
    "        print(\"Step 4 : Comprehension \")\n",
    "        # Comprehension\n",
    "        comp_output = [[comprehension_model(question=\"What is coronavirus\", \n",
    "                                     context = passage_id_map[pass_id]),  pass_id, pass_score] \\\n",
    "                  for pass_id, pass_score in final_results.items() if len(passage_id_map[pass_id].split()) > 5] \n",
    "\n",
    "        # Adding pass id and score to the comprehension\n",
    "        [comp_output[i][0].update({'pass_id': comp_output[i][1], \n",
    "                             'pass_rank_score': comp_output[i][2]}) for i in range(len(comp_output))]\n",
    "        \n",
    "        # Converting list of dictionaries of ranked results to dataframe.\n",
    "        comprehension_df = pd.DataFrame([comp_[0] for comp_ in comp_output])\n",
    "        \n",
    "        # adding query and the task\n",
    "        comprehension_df[\"query\"] = query\n",
    "        comprehension_df[\"task\"] = task_query_dict[\"task\"]\n",
    "        \n",
    "        # Finally, using passage_id to replace with actual Paper Title and Context\n",
    "        comprehension_df[\"title\"] = [passage_id_title_map[pass_id] for pass_id in comprehension_df.pass_id]\n",
    "        \n",
    "        all_comprehension_df_list.append(comprehension_df)\n",
    "\n",
    "all_comprehension_df = pd.concat(all_comprehension_df_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(all_comprehension_df, all_metadata_df[[\"passage_id\",\"passage\"]], \n",
    "         left_on = \"pass_id\", right_on = \"passage_id\", how = \"left\").to_csv(\"all_question_comprehension.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfqna",
   "language": "python",
   "name": "tfqna"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
